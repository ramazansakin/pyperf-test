# Performance Test Configuration Template
# ====================================
# This is a template configuration file for the API Performance Test Runner.
# Copy this file to 'config.yaml' and modify it according to your API testing needs.

# Base Configuration
# -----------------
# Base URL of the API (including version if applicable)
base_url: "http://api.example.com/v1"

# Test Execution Settings
# ----------------------
# Number of concurrent workers (simulating concurrent users)
num_workers: 10

# Number of requests to send to each endpoint configuration
requests_per_endpoint: 100

# Number of times to repeat the entire test suite
num_test_runs: 3

# Global Headers
# --------------
# Headers to include in all requests (e.g., for authentication)
# Remove or modify these according to your API's requirements
default_headers:
  Content-Type: application/json
  Accept: application/json
  # Uncomment and update with your authentication method if needed
  # Authorization: "Bearer your_token_here"
  # X-API-Key: "your_api_key_here"

# Dynamic Data Generation
# ======================
# Define variables and generators that can be used in requests

# Static Variables
# ---------------
# Fixed values that can be referenced in endpoints
variables:
  # Example numeric ID
  item_id: 12345
  
  # Example string values
  username: "testuser"

# Dynamic Data Generators
# ----------------------
generators:
  # Random selection from a list
  search_term:
    type: "choice"
    values: ["test", "example", "demo", "search", "query", "find"]
    
  # Random number in range
  random_id:
    type: "randint"
    min: 1
    max: 10000
    
  # Random string with pattern
  random_string:
    type: "string"
    length: 10
    chars: "abcdefghijklmnopqrstuvwxyz0123456789"
    
  # Random email
  random_email:
    type: "email"
    
  # Random boolean
  random_bool:
    type: "boolean"
    
  # Current timestamp
  timestamp:
    type: "timestamp"
    
  # Random item from a list with weights
  weighted_choice:
    type: "weighted_choice"
    choices:
      - {value: "high", weight: 1}
      - {value: "medium", weight: 3}
      - {value: "low", weight: 6}

# Predefined Data Sets
# -------------------
datasets:
  # Example product categories
  categories: ["Electronics", "Clothing", "Books", "Home", "Sports"]
  
  # Example user agents
  user_agents:
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0"

# Numeric Ranges
# --------------
ranges:
  price_range:
    min: 10
    max: 1000
    step: 50
  
  user_age:
    min: 18
    max: 80

# Request Timeouts and Retries
# ---------------------------
# Global timeout for requests in seconds (overridable per endpoint)
timeout: 10

# Number of retries for failed requests (0 to disable)
max_retries: 2

# Delay between retries in seconds
retry_delay: 1

# Test Endpoints
# --------------
# Define the API endpoints to test along with their configurations
# Each endpoint can have its own method, headers, and request body
endpoints:
  # Example: GET request with dynamic path parameter
  - name: "Get Item by ID"
    method: GET
    path: "/items/$random{1,1000}"  # Random ID between 1 and 1000
    description: "Test retrieving an item by its ID with random IDs"
    # You can also use a range from the configuration
    # path: "/items/$range{price_range}"
    # Optional: Override global timeout for this specific endpoint
    timeout: 5
    # Optional: Add endpoint-specific headers
    headers:
      X-Custom-Header: "value"

  # Example: Search endpoint with dynamic query parameter
  - name: "Search Items"
    method: GET
    path: "/search"
    description: "Test searching items with dynamic query parameters"
    # Dynamic parameters - these will be evaluated for each request
    params:
      q: "$random{search_term}"  # Randomly selects from predefined search terms
      category: "$random{categories}"  # Random category from dataset
      min_price: "$random{10,100}"  # Random number between 10 and 100
      in_stock: "$random{true,false}"  # Random boolean
      limit: 10
      offset: 0

  # Example: POST request with dynamic JSON body
  - name: "Create New Item"
    method: POST
    path: "/items"
    description: "Test creating a new item with dynamic data"
    # Dynamic request body - values will be generated for each request
    data:
      id: "$uuid"  # Generate a UUID
      name: "Product $random{1000,9999}"  # Random product name
      description: "$lorem{10}"  # 10 words of lorem ipsum
      price: "$random{10.0,1000.0}"  # Random float between 10.0 and 1000.0
      category: "$random{categories}"  # Random category from dataset
      in_stock: "$random{true,false}"  # Random boolean
      stock_quantity: "$random{0,1000}"  # Random integer
      created_at: "$now"  # Current timestamp
      tags: 
        - "$random{tag1,tag2,tag3,tag4}"  # Random tag from list
        - "$random{premium,standard,basic}"
      metadata:
        color: "$random{red,green,blue,black,white}"
        size: "$random{S,M,L,XL}"
        weight: "$random{0.1,5.0}"
    # Set to false if sending form data instead of JSON
    json_content: true

  # Example: PUT request with dynamic data
  - name: "Update Item"
    method: PUT
    path: "/items/${item_id}"
    description: "Test updating an existing item"
    data:
      name: "Updated Item"
      price: 109.99
      # You can use any Python expression in ${...} that references variables
      discount: "${price_range.min / 100}"

  # Example: DELETE request
  - name: "Delete Item"
    method: DELETE
    path: "/items/${item_id}"
    description: "Test deleting an item"

  # Example: Endpoint with authentication
  - name: "User Profile"
    method: GET
    path: "/users/${username}/profile"
    description: "Test accessing authenticated user profile"
    # Override global headers if needed
    headers:
      Authorization: "Bearer ${auth_token}"  # You would define auth_token in variables

# Test Scenarios (Optional)
# ------------------------
# Define different test scenarios with different configurations
scenarios:
  # Example: Smoke test with minimal load
  smoke_test:
    num_workers: 1
    requests_per_endpoint: 5
    num_test_runs: 1
    endpoints:
      - "Get Item by ID"
      - "Search Items"
  
  # Example: Load test with higher concurrency
  load_test:
    num_workers: 50
    requests_per_endpoint: 1000
    num_test_runs: 3

# Reporting Configuration
# ---------------------
report:
  # Directory to save HTML reports
  output_dir: "reports"
  
  # Include detailed request/response in the report
  include_request_details: true
  
  # Include response body in the report (may contain sensitive data)
  include_response_body: false
  
  # Generate a timestamp for each report file
  timestamp_format: "%Y%m%d_%H%M%S"

# Logging Configuration
# --------------------
log:
  # Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  level: "INFO"
  
  # Log file path (leave empty to log to console only)
  file: "performance_tests.log"
  
  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Advanced Configuration
# ---------------------
# SSL/TLS settings (for HTTPS connections)
ssl:
  # Verify SSL certificates (set to false for self-signed certificates)
  verify: true
  
  # Path to CA bundle file if needed
  # ca_bundle: "/path/to/ca_bundle.pem"

# Proxy configuration (if needed)
# proxy:
#   http: "http://proxy.example.com:8080"
#   https: "https://proxy.example.com:8080"

# Rate limiting (requests per second per worker)
rate_limit: 100

# Random delays between requests to simulate real user behavior
# (in seconds, can be a range [min, max] or a fixed value)
request_delay: [0.1, 0.5]
